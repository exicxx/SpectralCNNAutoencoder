digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	7417174352 [label="
 (1, 16, 973)" fillcolor=darkolivegreen1]
	7416251104 -> 7417174112 [dir=none]
	7417174112 [label="input
 (1, 32, 1946)" fillcolor=orange]
	7416251104 -> 7262059392 [dir=none]
	7262059392 [label="weight
 (16, 32, 3)" fillcolor=orange]
	7416251104 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:          (16,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :          False
weight        : [saved tensor]"]
	7416252208 -> 7416251104
	7416252208 -> 4524127552 [dir=none]
	4524127552 [label="input
 (1, 64, 3891)" fillcolor=orange]
	7416252208 -> 7262059232 [dir=none]
	7262059232 [label="weight
 (32, 64, 3)" fillcolor=orange]
	7416252208 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:          (32,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :          False
weight        : [saved tensor]"]
	7416254320 -> 7416252208
	7416254320 -> 7419210544 [dir=none]
	7419210544 [label="input
 (1, 1, 7781)" fillcolor=orange]
	7416254320 -> 7262059072 [dir=none]
	7262059072 [label="weight
 (64, 1, 3)" fillcolor=orange]
	7416254320 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:          (64,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :          False
weight        : [saved tensor]"]
	7416253648 -> 7416254320
	7262059072 [label="encoder1.weight
 (64, 1, 3)" fillcolor=lightblue]
	7262059072 -> 7416253648
	7416253648 [label=AccumulateGrad]
	7416253504 -> 7416254320
	7262059152 [label="encoder1.bias
 (64)" fillcolor=lightblue]
	7262059152 -> 7416253504
	7416253504 [label=AccumulateGrad]
	7416252160 -> 7416252208
	7262059232 [label="encoder2.weight
 (32, 64, 3)" fillcolor=lightblue]
	7262059232 -> 7416252160
	7416252160 [label=AccumulateGrad]
	7416252736 -> 7416252208
	7262059312 [label="encoder2.bias
 (32)" fillcolor=lightblue]
	7262059312 -> 7416252736
	7416252736 [label=AccumulateGrad]
	7416253888 -> 7416251104
	7262059392 [label="encoder3.weight
 (16, 32, 3)" fillcolor=lightblue]
	7262059392 -> 7416253888
	7416253888 [label=AccumulateGrad]
	7416254416 -> 7416251104
	7262059472 [label="encoder3.bias
 (16)" fillcolor=lightblue]
	7262059472 -> 7416254416
	7416254416 [label=AccumulateGrad]
	7416251104 -> 7417174352
}
